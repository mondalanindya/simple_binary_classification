{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mondalanindya/simple_binary_classification/blob/main/Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Harikrishnan6336/Mask_Classifier.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERBCGyzniPdM",
        "outputId": "e83dd043-c7ff-4015-b97b-5ae0dfc184b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mask_Classifier'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 66 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), 15.92 MiB | 2.23 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h7ULXysL6OF"
      },
      "source": [
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for reading and augmenting images\n",
        "from skimage.io import imread\n",
        "from skimage.transform import rotate, resize\n",
        "\n",
        "# for splitting train-test set and evaluating the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# PyTorch libraries \n",
        "import torch\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Make sure the images.zip is in the same directory and same path\n",
        "# loading dataset\n",
        "!unzip '/content/Mask_Classifier/data/images.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDcvDnLFNmvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9c17c3-1fac-4562-c779-4bae3429ea18"
      },
      "source": [
        "train = pd.read_csv('/content/Mask_Classifier/csv/mask.csv')\n",
        "\n",
        "# loading training images\n",
        "train_img = []\n",
        "train_img_values = []\n",
        "for img_name in train['image_names']:\n",
        "    image_path = '/content/images/' + img_name \n",
        "    img = imread(image_path)\n",
        "    img = img/255\n",
        "    img = resize(img, output_shape=(3, 224, 224),\n",
        "                 mode='constant', anti_aliasing=True)\n",
        "    train_img.append(img)\n",
        "\n",
        "\n",
        "train_x = np.array(train_img)\n",
        "\n",
        "# defining the labels\n",
        "train_y = train['mask_or_not'].values\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.2, random_state=13, stratify=train_y)\n",
        "print(\"Number of images (Before Image Augmentation) in Training set : \",train_x.shape[0],\"  Number of images in Testing set : \",test_x.shape[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images (Before Image Augmentation) in Training set :  652   Number of images in Testing set :  164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SCqqa-MZAYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4cc6285-abff-49a3-b1f7-abf43b561e4e"
      },
      "source": [
        "# Image Augmentation\n",
        "final_train_x = []\n",
        "final_train_y = []\n",
        "\n",
        "#train_x.shape[0]\n",
        "for i in range(train_x.shape[0]):\n",
        "    final_train_x.append(train_x[i])\n",
        "    final_train_x.append(rotate(train_x[i], angle=45, mode = 'wrap'))\n",
        "    final_train_x.append(np.fliplr(train_x[i]))\n",
        "    for j in range(3):\n",
        "      final_train_y.append(train_y[i])\n",
        "\n",
        "train_x = np.array(final_train_x)\n",
        "train_y = np.array(final_train_y)\n",
        "print(\"Number of images (After Image Augmentation) in Training set : \",train_x.shape[0],\"  Number of images in Testing set : \",test_x.shape[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images (After Image Augmentation) in Training set :  1956   Number of images in Testing set :  164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTrDGEXjZFXP"
      },
      "source": [
        "# converting training images and its labels into torch format\n",
        "train_x = train_x.reshape(1956, 3, 224, 224) #1956 is the number of training images\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "train_x = train_x.float()\n",
        "train_y = train_y.astype(int)\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "\n",
        "# converting test images and its labels into torch format\n",
        "test_x = test_x.reshape(164, 3, 224, 224) #164 is the number of test images\n",
        "test_x  = torch.from_numpy(test_x)\n",
        "test_x = test_x.float()\n",
        "test_y = test_y.astype(int)\n",
        "test_y = torch.from_numpy(test_y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e64QU28qZikr"
      },
      "source": [
        "# Define the model\n",
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(32),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(64),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "            Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(128),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(128),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(128 * 14 * 14, 512),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(512, 256),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(256,10),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(10,2)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSCCDRqjZi9W"
      },
      "source": [
        "model = Net()\n",
        "optimizer = Adam(model.parameters(), lr=0.000075)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk7rrwTjZjVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8071866f-567b-453a-e6fa-18eaa2fbb09d"
      },
      "source": [
        "# batch size of the model\n",
        "batch_size = 32\n",
        "\n",
        "# number of epochs to train the model\n",
        "n_epochs = 13\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    permutation = torch.randperm(train_x.size()[0])\n",
        "    training_loss = []\n",
        "    for i in range(0,train_x.size()[0], batch_size):\n",
        "\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs,batch_y)\n",
        "\n",
        "        training_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "        \n",
        "    training_loss = np.average(training_loss)\n",
        "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 1 \t training loss: \t 0.6175704237914854\n",
            "epoch: \t 2 \t training loss: \t 0.4488108037940918\n",
            "epoch: \t 3 \t training loss: \t 0.35936239962616273\n",
            "epoch: \t 4 \t training loss: \t 0.3010265489499415\n",
            "epoch: \t 5 \t training loss: \t 0.2898411383071253\n",
            "epoch: \t 6 \t training loss: \t 0.2612957931574314\n",
            "epoch: \t 7 \t training loss: \t 0.26864717191746157\n",
            "epoch: \t 8 \t training loss: \t 0.25979387718102626\n",
            "epoch: \t 9 \t training loss: \t 0.2461569460649644\n",
            "epoch: \t 10 \t training loss: \t 0.22173447967056306\n",
            "epoch: \t 11 \t training loss: \t 0.2058569922322227\n",
            "epoch: \t 12 \t training loss: \t 0.19391008009833674\n",
            "epoch: \t 13 \t training loss: \t 0.2262117370302158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVCi4uRSZ8V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392df796-afee-4318-d29c-72929486f861"
      },
      "source": [
        "# batch size of the model\n",
        "batch_size = 64\n",
        "# prediction for training set\n",
        "prediction = []\n",
        "target = []\n",
        "permutation = torch.randperm(train_x.size()[0])\n",
        "for i in range(0,train_x.size()[0], batch_size):\n",
        "    indices = permutation[i:i+batch_size]\n",
        "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(batch_x.cuda())\n",
        "\n",
        "    softmax = torch.exp(output).cpu()\n",
        "    prob = list(softmax.numpy())\n",
        "    predictions = np.argmax(prob, axis=1)\n",
        "    prediction.append(predictions)\n",
        "    target.append(batch_y)\n",
        "    \n",
        "# training accuracy\n",
        "accuracy = []\n",
        "for i in range(len(prediction)):\n",
        "    accuracy.append(accuracy_score(target[i].cpu(),prediction[i]))\n",
        "    \n",
        "print('training accuracy: \\t', np.average(accuracy))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: \t 0.9307795698924731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sJqaI5Z8tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1325adf4-5458-4f21-8a2b-4ae82d83eb3a"
      },
      "source": [
        "# checking the performance on validation set\n",
        "torch.manual_seed(0)\n",
        "# batch size of the model\n",
        "batch_size = 64\n",
        "# prediction for test set\n",
        "prediction = []\n",
        "target = []\n",
        "permutation = torch.randperm(test_x.size()[0])\n",
        "for i in range(0,test_x.size()[0], batch_size):\n",
        "    indices = permutation[i:i+batch_size]\n",
        "    batch_x, batch_y = test_x[indices], test_y[indices]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(batch_x.cuda())\n",
        "\n",
        "    softmax = torch.exp(output).cpu()\n",
        "    prob = list(softmax.numpy())\n",
        "    predictions = np.argmax(prob, axis=1)\n",
        "    prediction.append(predictions)\n",
        "    target.append(batch_y)\n",
        "    \n",
        "# Test accuracy\n",
        "accuracy = []\n",
        "for i in range(len(prediction)):\n",
        "    accuracy.append(accuracy_score(target[i].cpu(),prediction[i]))\n",
        "    \n",
        "print('Test accuracy: \\t', np.average(accuracy))\n",
        "torch.save(model, 'CNN-model.pth')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: \t 0.8877314814814815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufb2xKuoQRU5"
      },
      "source": [
        "The below code is used to test the model with a specific image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XZmpdgYAANm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03404f24-ad57-4051-fdfe-7cf3f5a3cd48"
      },
      "source": [
        "model = torch.load('CNN-model.pth')\n",
        "image_path = 'images/410.jpg' #Specify the image path\n",
        "img = imread(image_path)\n",
        "img = img/255\n",
        "img = resize(img, output_shape=(3, 224, 224),\n",
        "               mode='constant', anti_aliasing=True)\n",
        "img = img.astype('float32')\n",
        "img = np.array(img)\n",
        "\n",
        "img = img.reshape(1, 3, 224, 224) \n",
        "img = torch.from_numpy(img)\n",
        "img = img.float()\n",
        "\n",
        "output = model(img.cuda())\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.detach().numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "print(predictions)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    }
  ]
}