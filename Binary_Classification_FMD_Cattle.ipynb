{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mondalanindya/simple_binary_classification/blob/main/Binary_Classification_FMD_Cattle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FMD Cattle Dataset\n",
        "\n",
        "The [FMD Cattle](https://zenodo.org/record/7778370/files/FMD_Cattle.zip) is a collection of cattle images with and without foot and mouth diseases. In this dataset, the healthy animals are marked by class \"0\" and diseased animals are marked by class \"1\". So it's a dataset with two classes.\n",
        "\n",
        "In this project, we will implement a convolutional neural network (CNN) model for classifying the images of the FMD Cattle dataset. We will use PyTorch deep learning framework to complete our task."
      ],
      "metadata": {
        "id": "2F3kivrdltBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('FMD_Cattle'):\n",
        "    !wget https://zenodo.org/record/7779246/files/FMD_Cattle.zip\n",
        "    !unzip -q FMD_Cattle.zip\n",
        "    !rm FMD_Cattle.zip"
      ],
      "metadata": {
        "id": "nGq4Fk3PZWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation of some extra packages"
      ],
      "metadata": {
        "id": "0B6-43k1p3Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of grad cam\n",
        "!pip3 install grad-cam\n",
        "!pip3 install torchmetrics"
      ],
      "metadata": {
        "id": "51Q4EbUYplTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset and DataLoader"
      ],
      "metadata": {
        "id": "iEAsP5FRfTSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, we will be defining datasets and data loaders necessary for our training. Details on datasets and dataloaders can be found in the [documentation](https://pytorch.org/vision/stable/datasets.html)."
      ],
      "metadata": {
        "id": "0nFCiLJOh3Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "\n",
        "# Before defining datasets, lets define how images should be transformed. This is \n",
        "# because the transformations should go with the definitions of datasets. In this\n",
        "# tutorial we will using simple transformations, such as (1) image to tensor, (2)\n",
        "# normalization.\n",
        "image_transform = Compose([Resize((112, 112)), ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# To visualize the normalized images, we need to apply inverse transformation which \n",
        "# can be implemented as follows\n",
        "inv_normalize = Compose([Normalize(mean = [0., 0., 0. ], std = [1/0.5, 1/0.5, 1/0.5 ]), Normalize(mean = [-0.5, -0.5, -0.5], std = [1., 1., 1. ]),])\n",
        "\n",
        "# Once we have the transformations defined, lets define the dataset\n",
        "dataset = ImageFolder('FMD_Cattle', transform=image_transform)\n",
        "\n",
        "# Once we have the dataset, lets split it into train and test set in 80% and 20%\n",
        "# ratio in a stratified fashion.\n",
        "train_idx, test_idx = train_test_split(np.arange(len(dataset)), test_size=0.2, random_state=42, shuffle=True, stratify=dataset.targets)\n",
        "\n",
        "# Subset dataset for train and test\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "# Once we have the datasets defined, lets define the data loaders as follows\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "R8N2vhP8a3Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdYlqJ7xDvJa",
        "pycharm": {}
      },
      "source": [
        "### Example Image\n",
        "Lets have a look on how images from FMD_Cattle dataset looks like. Since the images are already normalized, their resolutions might have slightly changed. To visualize the original images, we should have ideally apply a reverse transformation which is avoided to keep this tutorial simple and brief."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4FrTxdxDwnE",
        "pycharm": {}
      },
      "source": [
        "# import plot library\n",
        "import matplotlib.pyplot as plt\n",
        "# iterate the dataloader\n",
        "_, (example_datas, labels) = next(enumerate(train_loader))\n",
        "# get the first data\n",
        "sample = inv_normalize(example_datas[0])\n",
        "# show the data\n",
        "plt.imshow(sample.permute(1, 2, 0))\n",
        "print(\"Label: \" + str(labels[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUWGhlsMCYZD",
        "pycharm": {}
      },
      "source": [
        "## Model\n",
        "Now, we have to define trainable layers with parameters and put them inside a model. Have a look on the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#module) of `nn.Module` and read more about different layers and functionalities of PyTorch there. Here we are going to implement various versions of AlexNet model and use it for classification. In this model, we are going to use the following functions or modules:\n",
        "\n",
        "* `nn.Conv2d()`: It is a PyTorch module that applies a 2D convolution over an input signal composed of several input planes. More details are available on the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "\n",
        "* `nn.Linear()`: It is a module that applies a linear transformation to the incoming data. More details can be found in its [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear).\n",
        "\n",
        "* `nn.ReLU()`: It is also a module that applies element-wise the rectified linear unit function. Its [documentation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu) can explain more.\n",
        "\n",
        "* `nn.Dropout()`: This module randomly zeroes some of the elements of the input tensor with probability `p`. Check the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One can define a model in several ways. Below, we show some of them."
      ],
      "metadata": {
        "id": "yjGEol-IX31p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMtPp5OeCakG",
        "pycharm": {}
      },
      "source": [
        "## We first import the pytorch nn module and optimizer\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "## Below we define the model as defined in the torchvision package and initialised \n",
        "## with pretrained weights (see pretrained=True flag)\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet, self).__init__()\n",
        "        from torchvision import models\n",
        "        alexnet = models.alexnet(weights='IMAGENET1K_V1')\n",
        "        self.features = alexnet.features\n",
        "        self.avgpool = alexnet.avgpool\n",
        "        self.classifier = alexnet.classifier\n",
        "        # Please note how to change the last layer of the classifier for a new dataset\n",
        "        # ImageNet-1K has 1000 classes, but STL-10 has 10 classes\n",
        "        self.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        # Note how we are flattening the feature map, B x C x H x W -> B x C*H*W\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nayicPkJCkWy",
        "pycharm": {}
      },
      "source": [
        "## Initialization\n",
        "Once we have the model defined, lets instantiate it and set other hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model\n",
        "We will initialize the model, transfer to the desired device and set the parameters to receive gradients."
      ],
      "metadata": {
        "id": "Y6YBtqhvZGwG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjyEGZSdCk_i",
        "pycharm": {}
      },
      "source": [
        "# define the model, we use AlexNet\n",
        "model = AlexNet(2) # since FMD Cattle dataset has 2 classes, we set num_classes = 2\n",
        "# device: cuda (gpu) or cpu\n",
        "device = \"cuda\"\n",
        "# map to device\n",
        "model = model.to(device) # `model.cuda()` will also do the same job\n",
        "# make the parameters trainable\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizer\n",
        "For updating the parameters, PyTorch provides the package torch.optim that has most popular optimizers implemented. In this tutorial, we will be using the `torch.optim.Adam` optimizer.\n"
      ],
      "metadata": {
        "id": "CETvGvW8Y5-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "## some hyperparameters related to optimizer\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.0005\n",
        "# define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "jEBBRoh-Y-bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "-RkqO0VcZuRP"
      },
      "source": [
        "## Average Meter\n",
        "It is a simple class for keeping training statistics, such as losses and accuracies etc. The `.val` field usually holds the statistics for the current batch, whereas the `.avg` field hold statistics for the current epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeLH7fbOHDhH",
        "pycharm": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSk4VfO_C4tL",
        "pycharm": {}
      },
      "source": [
        "## Train and Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJeHMF_BC7bg",
        "pycharm": {}
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "##define train function\n",
        "def train(model, device, train_loader, optimizer):\n",
        "    # meter\n",
        "    loss = AverageMeter()\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
        "    for batch_idx, (data, target) in enumerate(tk0):\n",
        "        # after fetching the data transfer the model to the \n",
        "        # required device, in this example the device is gpu\n",
        "        # transfer to gpu can also be done by \n",
        "        # data, target = data.cuda(), target.cuda()\n",
        "        data, target = data.to(device), target.to(device)  \n",
        "        # compute the forward pass\n",
        "        # it can also be achieved by model.forward(data)\n",
        "        output = model(data) \n",
        "        # compute the loss function\n",
        "        loss_this = F.cross_entropy(output, target)\n",
        "        # initialize the optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # compute the backward pass\n",
        "        loss_this.backward()\n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        # update the loss meter \n",
        "        loss.update(loss_this.item(), target.shape[0])\n",
        "    print('Train: Average loss: {:.4f}\\n'.format(loss.avg))\n",
        "    return loss.avg\n",
        "        \n",
        "##define test function\n",
        "def test(model, device, test_loader):\n",
        "    # meters\n",
        "    loss = AverageMeter()\n",
        "    acc = AverageMeter()\n",
        "    correct = 0\n",
        "    # switch to test mode\n",
        "    model.eval()\n",
        "    for data, target in test_loader:\n",
        "        # after fetching the data transfer the model to the \n",
        "        # required device, in this example the device is gpu\n",
        "        # transfer to gpu can also be done by \n",
        "        # data, target = data.cuda(), target.cuda()\n",
        "        data, target = data.to(device), target.to(device)  # data, target = data.cuda(), target.cuda()\n",
        "        # since we dont need to backpropagate loss in testing,\n",
        "        # we dont keep the gradient\n",
        "        with torch.no_grad():\n",
        "            # compute the forward pass\n",
        "            # it can also be achieved by model.forward(data)\n",
        "            output = model(data)\n",
        "        # compute the loss function just for checking\n",
        "        loss_this = F.cross_entropy(output, target) # sum up batch loss\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.argmax(dim=1, keepdim=True) \n",
        "        # check which of the predictions are correct\n",
        "        correct_this = pred.eq(target.view_as(pred)).sum().item()\n",
        "        # accumulate the correct ones\n",
        "        correct += correct_this\n",
        "        # compute accuracy\n",
        "        acc_this = correct_this/target.shape[0]*100.0\n",
        "        # update the loss and accuracy meter \n",
        "        acc.update(acc_this, target.shape[0])\n",
        "        loss.update(loss_this.item(), target.shape[0])\n",
        "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        loss.avg, correct, len(test_loader.dataset), acc.avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzxivyrXDB7a",
        "pycharm": {}
      },
      "source": [
        "## Training Loop\n",
        "Training loop containing alternating train and test phase. Below we are iterating the loops 5 times, you can iterate more times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tna_R8TSDD4D",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "# number of epochs we decide to train\n",
        "num_epoch = 5\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "    epoch_loss = train(model, device, train_loader, optimizer)\n",
        "test(model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B19bDzBDIV4",
        "pycharm": {}
      },
      "source": [
        "### Summary\n",
        "Show the summary of the model. It shows the number of parameters in layerwise as well as the total number of parameters. It also shows the memories required for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eztTJ4VDKCA",
        "pycharm": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 112, 112))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Confusion matrix\n",
        "\n",
        "By definition a confusion matrix $C$ is such that $C_{i, j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$. Thus in binary classification, the count of true negatives is $C_{0,0}$, false negatives is $C_{1,0}$, true positives is $C_{1,1}$ and false positives is $C_{0,1}$."
      ],
      "metadata": {
        "id": "r3g5gPUsqV7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute and accumulate predictions and targets"
      ],
      "metadata": {
        "id": "GScv5wesCKFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "preds = []\n",
        "for data, target in test_loader:\n",
        "    # after fetching the data transfer the model to the \n",
        "    # required device, in this example the device is gpu\n",
        "    # transfer to gpu can also be done by \n",
        "    data = data.to(device) # data, target = data.cuda(), target.cuda()\n",
        "    # since we dont need to backpropagate loss in testing,\n",
        "    # we dont keep the gradient\n",
        "    with torch.no_grad():\n",
        "        # compute the forward pass\n",
        "        output = model(data)\n",
        "    # get the index of the max log-probability\n",
        "    pred_this = output.argmax(dim=1, keepdim=True) \n",
        "    # accumulate the correct ones\n",
        "    preds += pred_this.cpu().squeeze().tolist()\n",
        "    targets += target.tolist()"
      ],
      "metadata": {
        "id": "MoftSbT8qFLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute confusion matrix"
      ],
      "metadata": {
        "id": "NeNTXfwqCSUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import BinaryConfusionMatrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
        "bcm = BinaryConfusionMatrix()\n",
        "cm = bcm(torch.tensor(preds), torch.tensor(targets))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm.numpy())\n",
        "disp.plot();"
      ],
      "metadata": {
        "id": "QTpPwykuvRS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Display classified images"
      ],
      "metadata": {
        "id": "-4UEMYvVtCV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for displaying images"
      ],
      "metadata": {
        "id": "Okg76Q8zbNKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = TF.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "# show images in grid\n",
        "def show_images_grid(indices):\n",
        "    image_list = []\n",
        "    for idx in indices:\n",
        "        x, _ = test_loader.dataset[idx]\n",
        "        image_list += inv_normalize(x.unsqueeze(0))\n",
        "    if len(image_list):\n",
        "        grid = make_grid(image_list)\n",
        "        show(grid)\n",
        "\n",
        "# show individual images\n",
        "def show_images_indv(indices):\n",
        "    for idx in indices:\n",
        "        x = test_loader.dataset[idx][0]\n",
        "        x = inv_normalize(x).permute(1, 2, 0).numpy()\n",
        "        plt.imshow(x)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "rZm48Lng2iiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Correctly classified examples"
      ],
      "metadata": {
        "id": "VK50lwV-ss1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Getting the indices\n",
        "idx_targets0_preds0 = np.where((np.array(targets) == 0) & (np.array(preds) == 0))[0].tolist()\n",
        "idx_targets1_preds1 = np.where((np.array(targets) == 1) & (np.array(preds) == 1))[0].tolist()"
      ],
      "metadata": {
        "id": "J_4c4d9ksxvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Healthy animals correctly classified as healthy animals"
      ],
      "metadata": {
        "id": "4GWnd5ZjUWvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
        "show_images_grid(idx_targets0_preds0)\n",
        "# plt.rcParams[\"figure.figsize\"] = [2.5, 2.5]\n",
        "# show_images_indv(idx_targets0_preds0)"
      ],
      "metadata": {
        "id": "Pzh6NtZFAfYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Diseased animals correctly classified as diseased animals"
      ],
      "metadata": {
        "id": "fTQeZTpzUiMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
        "show_images_grid(idx_targets1_preds1)\n",
        "# plt.rcParams[\"figure.figsize\"] = [2.5, 2.5]\n",
        "# show_images_indv(idx_targets1_preds1)"
      ],
      "metadata": {
        "id": "G41ALyzKAgQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Misclassified examples"
      ],
      "metadata": {
        "id": "BOWu3s3SwlU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx_targets0_preds1 = np.where((np.array(targets) == 0) & (np.array(preds) == 1))[0].tolist()\n",
        "idx_targets1_preds0 = np.where((np.array(targets) == 1) & (np.array(preds) == 0))[0].tolist()"
      ],
      "metadata": {
        "id": "rSI0JPqYxARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Healthy animals wrongly classified as diseased animals"
      ],
      "metadata": {
        "id": "vhZ3jfUbXQo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
        "show_images_grid(idx_targets0_preds1)\n",
        "# plt.rcParams[\"figure.figsize\"] = [2.5, 2.5]\n",
        "# show_images_indv(idx_targets0_preds1)"
      ],
      "metadata": {
        "id": "yINx40pjXF5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Diseased animals wrongly classified as healthy animals"
      ],
      "metadata": {
        "id": "bia2HRwJXXxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [5, 5]\n",
        "show_images_grid(idx_targets1_preds0)\n",
        "# plt.rcParams[\"figure.figsize\"] = [2.5, 2.5]\n",
        "# show_images_indv(idx_targets1_preds0)"
      ],
      "metadata": {
        "id": "pwJQkGFEXMeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Explanations of classifier decisions"
      ],
      "metadata": {
        "id": "syBP6VsibpsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This explains for which regions (or which image features) in the image the decision is made. Red regions show high level of activations, whereas blue regions show low level of activation. In other words, the features from the red regions are responsible for the classifier decision."
      ],
      "metadata": {
        "id": "6b_M3PMDq07D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "plt.rcParams[\"figure.figsize\"] = [2.5, 2.5]\n",
        "target_layers = model.features\n",
        "cam = GradCAM(model, target_layers=target_layers, use_cuda=False)\n",
        "gs_cam = cam(input_tensor=data, eigen_smooth=True)\n",
        "for idx in range(len(test_loader.dataset)):\n",
        "    x = test_loader.dataset[idx][0]\n",
        "    rgb_img = inv_normalize(x).permute(1, 2, 0).numpy()\n",
        "    cam_img = show_cam_on_image(rgb_img, gs_cam[idx, :], use_rgb=True, image_weight=0.5)\n",
        "    plt.imshow(cam_img)\n",
        "    plt.xlabel(\"Predicted: {}, Actual: {}\".format(preds[idx], targets[idx]))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ls8c5C2se4Ml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}